{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import ComparePoseModels\n",
    "\n",
    "inferencer = ComparePoseModels(\n",
    "    predictions_dir='../predictions/',\n",
    "    gt_dir='../data/ground_truth',\n",
    "    output_dir='./results',\n",
    "    scale=True,\n",
    "    pck_treshold=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments**\n",
    "- predictions_dir: folder where prediction results are. if single_file is true, then path to specific CSV\n",
    "- gt_dir: folder where ground truth CSVs are. if single_file is true, then path to specific CSV\n",
    "- output_dir: folder where evaluation results will be stored. defaults to prediction_dir\n",
    "- single_file: True when there is a single file that needs evaluating. if True, prediction and gt directories need to point to the specific file. defaults to False\n",
    "- pck_threshold: threshold of how close the prediction needs to be to the ground truth to count as correct prediction. when scale = False defaults to 10 pixels, when scale = True defaults to 0.125 (= 12.5%) of hip-neck distance\n",
    "- scale: True when evaluation measures with respect to the scale of the subject. False when evaluation measures with predefined pixel distance. defaults to True\n",
    "- confidence: required minimum confidence threshold of the predictions. defaults to '0.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.evaluate_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.compare_models(save_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.environmental_factors(env_csv='/path/to/your/environment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find an example `environment.csv` in the 'evaluation' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.visualisation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
